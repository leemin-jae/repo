{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c1be75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "497637b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.7.0-cp38-cp38-win_amd64.whl (430.8 MB)\n",
      "Collecting gast<0.5.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\82106\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow) (1.14.0)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.19.1-cp38-cp38-win_amd64.whl (895 kB)\n",
      "Collecting tensorflow-estimator<2.8,~=2.7.0rc0\n",
      "  Downloading tensorflow_estimator-2.7.0-py2.py3-none-any.whl (463 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.42.0-cp38-cp38-win_amd64.whl (3.3 MB)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\82106\\anaconda3\\lib\\site-packages (from tensorflow) (1.20.1)\n",
      "Collecting tensorboard~=2.6\n",
      "  Downloading tensorboard-2.7.0-py3-none-any.whl (5.8 MB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in c:\\users\\82106\\anaconda3\\lib\\site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\82106\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\82106\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in c:\\users\\82106\\anaconda3\\lib\\site-packages (from tensorflow) (2.7.0)\n",
      "Collecting flatbuffers<3.0,>=1.12\n",
      "  Downloading flatbuffers-2.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting absl-py>=0.4.0\n",
      "  Downloading absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\82106\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow) (1.11.2)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.21.0\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.22.0-cp38-cp38-win_amd64.whl (1.5 MB)\n",
      "Collecting libclang>=9.0.1\n",
      "  Downloading libclang-12.0.0-py2.py3-none-win_amd64.whl (13.1 MB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\82106\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (52.0.0.post20210125)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\82106\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\82106\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.25.1)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.3.3-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Downloading importlib_metadata-4.8.2-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\82106\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.4.1)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\82106\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\82106\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\82106\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\82106\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "Building wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4829 sha256=abe3e46a8c1a2a8f383dffd95f33632e8cea02b27a9e8932f73aeda74de6f0c6\n",
      "  Stored in directory: c:\\users\\82106\\appdata\\local\\pip\\cache\\wheels\\a0\\16\\9c\\5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "Successfully built termcolor\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, opt-einsum, libclang, keras-preprocessing, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 3.10.0\n",
      "    Uninstalling importlib-metadata-3.10.0:\n",
      "      Successfully uninstalled importlib-metadata-3.10.0\n",
      "Successfully installed absl-py-1.0.0 astunparse-1.6.3 cachetools-4.2.4 flatbuffers-2.0 gast-0.4.0 google-auth-2.3.3 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.42.0 importlib-metadata-4.8.2 keras-preprocessing-1.1.2 libclang-12.0.0 markdown-3.3.6 oauthlib-3.1.1 opt-einsum-3.3.0 protobuf-3.19.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.8 tensorboard-2.7.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.7.0 tensorflow-estimator-2.7.0 tensorflow-io-gcs-filesystem-0.22.0 termcolor-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49faa014",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72a244f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.1.0-py3-none-any.whl (958 kB)\n",
      "Collecting trio~=0.17\n",
      "  Downloading trio-0.19.0-py3-none-any.whl (356 kB)\n",
      "Requirement already satisfied: urllib3[secure]~=1.26 in c:\\users\\82106\\anaconda3\\lib\\site-packages (from selenium) (1.26.4)\n",
      "Collecting trio-websocket~=0.9\n",
      "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\82106\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.14.5)\n",
      "Requirement already satisfied: idna in c:\\users\\82106\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.10)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\82106\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\82106\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.3.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\82106\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (20.3.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\82106\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Collecting outcome\n",
      "  Downloading outcome-1.1.0-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: pycparser in c:\\users\\82106\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.20)\n",
      "Collecting wsproto>=0.14\n",
      "  Downloading wsproto-1.0.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: cryptography>=1.3.4 in c:\\users\\82106\\anaconda3\\lib\\site-packages (from urllib3[secure]~=1.26->selenium) (3.4.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\82106\\anaconda3\\lib\\site-packages (from urllib3[secure]~=1.26->selenium) (2020.12.5)\n",
      "Requirement already satisfied: pyOpenSSL>=0.14 in c:\\users\\82106\\anaconda3\\lib\\site-packages (from urllib3[secure]~=1.26->selenium) (20.0.1)\n",
      "Requirement already satisfied: six>=1.5.2 in c:\\users\\82106\\appdata\\roaming\\python\\python38\\site-packages (from pyOpenSSL>=0.14->urllib3[secure]~=1.26->selenium) (1.14.0)\n",
      "Collecting h11<1,>=0.9.0\n",
      "  Downloading h11-0.12.0-py3-none-any.whl (54 kB)\n",
      "Installing collected packages: outcome, h11, wsproto, trio, trio-websocket, selenium\n",
      "Successfully installed h11-0.12.0 outcome-1.1.0 selenium-4.1.0 trio-0.19.0 trio-websocket-0.9.2 wsproto-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3780c769",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file or directory found at keras_model.h5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-a0795dd66473>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Load the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'keras_model.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Create the array of the right shape to feed into the keras model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\saving\\save.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'No file or directory found at {filepath}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0msaving_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_hdf5_filepath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mh5py\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             raise ImportError(\n",
      "\u001b[1;31mOSError\u001b[0m: No file or directory found at keras_model.h5"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "\n",
    "# Load the model\n",
    "model = load_model('keras_model.h5')\n",
    "\n",
    "# Create the array of the right shape to feed into the keras model\n",
    "# The 'length' or number of images you can put into the array is\n",
    "# determined by the first position in the shape tuple, in this case 1.\n",
    "data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
    "# Replace this with the path to your image\n",
    "image = Image.open('<IMAGE_PATH>')\n",
    "#resize the image to a 224x224 with the same strategy as in TM2:\n",
    "#resizing the image to be at least 224x224 and then cropping from the center\n",
    "size = (224, 224)\n",
    "image = ImageOps.fit(image, size, Image.ANTIALIAS)\n",
    "\n",
    "#turn the image into a numpy array\n",
    "image_array = np.asarray(image)\n",
    "# Normalize the image\n",
    "normalized_image_array = (image_array.astype(np.float32) / 127.0) - 1\n",
    "# Load the image into the array\n",
    "data[0] = normalized_image_array\n",
    "\n",
    "# run the inference\n",
    "prediction = model.predict(data)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dff41c3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n",
      "read success!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# 카메라 캡쳐 객체, 0=내장 카메라\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "# 캡쳐 프레임 사이즈 조절\n",
    "capture.set(cv2.CAP_PROP_FRAME_WIDTH, 320)\n",
    "capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 240)\n",
    "\n",
    "while True: # 특정 키를 누를 때까지 무한 반복\n",
    "    # 한 프레임씩 읽기\n",
    "    ret, frame = capture.read()\n",
    "    if ret == True: \n",
    "        print(\"read success!\")\n",
    "    \n",
    "    # 이미지 뒤집기, 1=좌우 뒤집기\n",
    "    frame_fliped = cv2.flip(frame, 1)\n",
    "    \n",
    "    # 읽어들인 프레임을 윈도우창에 출력\n",
    "    cv2.imshow(\"VideoFrame\", frame_fliped)\n",
    "    \n",
    "    # 1ms동안 사용자가 키를 누르기를 기다림\n",
    "    if cv2.waitKey(1) > 0: \n",
    "        break \n",
    "        \n",
    "# 카메라 객체 반환\n",
    "capture.release()\n",
    " \n",
    "# 화면에 나타난 윈도우들을 종료\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b0fe53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001B23CC61A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[[9.9999976e-01 2.3561479e-07 2.7724225e-08]]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "\n",
    "# Load the model\n",
    "model = load_model('keras_model.h5')\n",
    "\n",
    "# Create the array of the right shape to feed into the keras model\n",
    "# The 'length' or number of images you can put into the array is\n",
    "# determined by the first position in the shape tuple, in this case 1.\n",
    "data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
    "# Replace this with the path to your image\n",
    "#image = Image.open('e4c7940c6516b506c5a9cfa21af604f9.jpg')\n",
    "image = Image.open('다운로드 (37).jpg')\n",
    "\n",
    "#resize the image to a 224x224 with the same strategy as in TM2:\n",
    "#resizing the image to be at least 224x224 and then cropping from the center\n",
    "size = (224, 224)\n",
    "image = ImageOps.fit(image, size, Image.ANTIALIAS)\n",
    "\n",
    "#turn the image into a numpy array\n",
    "image_array = np.asarray(image)\n",
    "# Normalize the image\n",
    "normalized_image_array = (image_array.astype(np.float32) / 127.0) - 1\n",
    "# Load the image into the array\n",
    "data[0] = normalized_image_array\n",
    "\n",
    "# run the inference\n",
    "prediction = model.predict(data)\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba5201ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7724225e-08"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f84cf8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "한복\n",
      "한복\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "한복\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "한복\n",
      "한복\n",
      "기모노\n",
      "한복\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "한복\n",
      "기모노\n",
      "기모노\n",
      "한복\n",
      "기모노\n",
      "한복\n",
      "한복\n",
      "한복\n",
      "한복\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n",
      "기모노\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import tensorflow.keras\n",
    "import numpy as np\n",
    "\n",
    "## 이미지 전처리\n",
    "def preprocessing(frame):\n",
    "    # 사이즈 조정\n",
    "    size = (224, 224)\n",
    "    frame_resized = cv2.resize(frame, size, interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    # 이미지 정규화\n",
    "    frame_normalized = (frame_resized.astype(np.float32) / 127.0) - 1\n",
    "    \n",
    "    # 이미지 차원 재조정 - 예측을 위해 reshape 해줍니다.\n",
    "    frame_reshaped = frame_normalized.reshape((1, 224, 224, 3))\n",
    "    \n",
    "    return frame_reshaped\n",
    "\n",
    "## 학습된 모델 불러오기\n",
    "model_filename = 'keras_model.h5'\n",
    "model = tensorflow.keras.models.load_model(model_filename)\n",
    "\n",
    "# 카메라 캡쳐 객체, 0=내장 카메라\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "# 캡쳐 프레임 사이즈 조절\n",
    "capture.set(cv2.CAP_PROP_FRAME_WIDTH, 320)\n",
    "capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 240)\n",
    "\n",
    "sleep_cnt = 1 # 30초간 \"졸림\" 상태를 확인하기 위한 변수\n",
    "while True:\n",
    "    ret, frame = capture.read()\n",
    "  #  if ret == True: \n",
    "  #      print(\"read success!\")\n",
    "\n",
    "    # 이미지 뒤집기\n",
    "    frame_fliped = cv2.flip(frame, 1)\n",
    "    \n",
    "    # 이미지 출력\n",
    "    cv2.imshow(\"VideoFrame\", frame_fliped)\n",
    "    \n",
    "    # 1초마다 검사하며, videoframe 창으로 아무 키나 누르게 되면 종료\n",
    "    if cv2.waitKey(200) > 0: \n",
    "        break\n",
    "    \n",
    "    # 데이터 전처리\n",
    "    preprocessed = preprocessing(frame_fliped)\n",
    "\n",
    "    # 예측\n",
    "    prediction = model.predict(preprocessed)\n",
    "    #print(prediction) # [[0.00533728 0.99466264]]\n",
    "    \n",
    "    if max(prediction[0]) == prediction[0,0]:\n",
    "        print('기모노')\n",
    "    elif max(prediction[0]) == prediction[0,1]:\n",
    "        print('한복')\n",
    "    \n",
    "    else:\n",
    "        print('깨어있는 상태')\n",
    "        sleep_cnt = 1\n",
    "    \n",
    "# 카메라 객체 반환\n",
    "capture.release() \n",
    "# 화면에 나타난 윈도우들을 종료\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c35457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "import json\n",
    "\n",
    "client_id = \"클라이언트 아이디\"\n",
    "client_secret = \"클라이언트 시크릿\"\n",
    "encText = urllib.parse.quote(\"검색어\")\n",
    "url = \"https://openapi.naver.com/v1/search/image?query=\" + encText\n",
    "\n",
    "request = urllib.request.Request(url)\n",
    "request.add_header(\"X-Naver-Client-Id\",client_id)\n",
    "request.add_header(\"X-Naver-Client-Secret\",client_secret)\n",
    "response = urllib.request.urlopen(request)\n",
    "rescode = response.getcode()\n",
    "\n",
    "# 이미지 저장 경로\n",
    "savePath = \"C:/python_crw/imagedown/\"\n",
    "\n",
    "if(rescode==200):\n",
    "    response_body = response.read()\n",
    "    result = json.loads(response_body)\n",
    "    img_list = result['items']\n",
    "\n",
    "    for i, img_list in enumerate(img_list, 1):\n",
    "        \n",
    "        # 이미지링크 확인\n",
    "        print(img_list['link'])\n",
    "\n",
    "        # 저장 파일명 및 경로\n",
    "        FileName = os.path.join(savePath, savePath + str(i) + '.jpg')\n",
    "        \n",
    "        # 파일명 출력 \n",
    "        print('full name : {}'.format(FileName))\n",
    "        \n",
    "        # 이미지 다운로드 URL 요청\n",
    "        urllib.request.urlretrieve(img_list['link'], FileName)\n",
    "\n",
    "    # 다운로드 완료 시 출력\n",
    "    print(\"--------download succeeded--------\")\n",
    "\n",
    "else:\n",
    "    print(\"Error Code:\" + rescode)\n",
    "[출처] 네이버 open API 이용해서 이미지 크롤링하고 결과를 파일로 저장하는 파이썬 코드|작성자 코딩하는 약사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b98214b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색어를 입력하세요 : 한복\n",
      "다운로드 완료\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "baseUrl = 'https://search.naver.com/search.naver?where=image&sm=tab_jum&query='\n",
    "plusUrl = input('검색어를 입력하세요 : ')\n",
    "# 한글 검색 자동 변환\n",
    "url = baseUrl + quote_plus(plusUrl)\n",
    "html = urlopen(url)\n",
    "soup = bs(html, \"html.parser\")\n",
    "img = soup.find_all(class_='_img')\n",
    "\n",
    "n = 1\n",
    "for i in img:\n",
    "    imgUrl = i['data-source']\n",
    "    with urlopen(imgUrl) as f:\n",
    "        with open('./img/' + plusUrl + str(n)+'.jpg','wb') as h: # w - write b - binary\n",
    "            img = f.read()\n",
    "            h.write(img)\n",
    "    n += 1\n",
    "print('다운로드 완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b2f3f87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-75bca14d15f2>:14: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  elem = browser.find_element_by_id('nx_query')\n",
      "<ipython-input-6-75bca14d15f2>:20: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  browser.find_element_by_xpath(\"//body\").send_keys(Keys.END)\n"
     ]
    },
    {
     "ename": "WebDriverException",
     "evalue": "Message: chrome not reachable\n  (Session info: chrome=96.0.4664.45)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00FF6903+2517251]\n\tOrdinal0 [0x00F8F8E1+2095329]\n\tOrdinal0 [0x00E92710+1058576]\n\tOrdinal0 [0x00E876A4+1013412]\n\tOrdinal0 [0x00E87EA8+1015464]\n\tOrdinal0 [0x00E89695+1021589]\n\tOrdinal0 [0x00E83686+996998]\n\tOrdinal0 [0x00E93A60+1063520]\n\tOrdinal0 [0x00EE5382+1397634]\n\tOrdinal0 [0x00ED639B+1336219]\n\tOrdinal0 [0x00EB27A7+1189799]\n\tOrdinal0 [0x00EB3609+1193481]\n\tGetHandleVerifier [0x01185904+1577972]\n\tGetHandleVerifier [0x01230B97+2279047]\n\tGetHandleVerifier [0x01086D09+534521]\n\tGetHandleVerifier [0x01085DB9+530601]\n\tOrdinal0 [0x00F94FF9+2117625]\n\tOrdinal0 [0x00F998A8+2136232]\n\tOrdinal0 [0x00F999E2+2136546]\n\tOrdinal0 [0x00FA3541+2176321]\n\tBaseThreadInitThunk [0x76B8FA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x772C7A9E+286]\n\tRtlGetAppContainerNamedObjectPath [0x772C7A6E+238]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-75bca14d15f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mbrowser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"//body\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEND\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element_by_xpath\u001b[1;34m(self, xpath)\u001b[0m\n\u001b[0;32m    518\u001b[0m             \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m         )\n\u001b[1;32m--> 520\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    521\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_elements_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mWebElement\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m   1242\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'[name=\"%s\"]'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1244\u001b[1;33m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[0m\u001b[0;32m   1245\u001b[0m             \u001b[1;34m'using'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1246\u001b[0m             'value': value})['value']\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 424\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    425\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    426\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    245\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mMapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_KT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_KT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: chrome not reachable\n  (Session info: chrome=96.0.4664.45)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00FF6903+2517251]\n\tOrdinal0 [0x00F8F8E1+2095329]\n\tOrdinal0 [0x00E92710+1058576]\n\tOrdinal0 [0x00E876A4+1013412]\n\tOrdinal0 [0x00E87EA8+1015464]\n\tOrdinal0 [0x00E89695+1021589]\n\tOrdinal0 [0x00E83686+996998]\n\tOrdinal0 [0x00E93A60+1063520]\n\tOrdinal0 [0x00EE5382+1397634]\n\tOrdinal0 [0x00ED639B+1336219]\n\tOrdinal0 [0x00EB27A7+1189799]\n\tOrdinal0 [0x00EB3609+1193481]\n\tGetHandleVerifier [0x01185904+1577972]\n\tGetHandleVerifier [0x01230B97+2279047]\n\tGetHandleVerifier [0x01086D09+534521]\n\tGetHandleVerifier [0x01085DB9+530601]\n\tOrdinal0 [0x00F94FF9+2117625]\n\tOrdinal0 [0x00F998A8+2136232]\n\tOrdinal0 [0x00F999E2+2136546]\n\tOrdinal0 [0x00FA3541+2176321]\n\tBaseThreadInitThunk [0x76B8FA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x772C7A9E+286]\n\tRtlGetAppContainerNamedObjectPath [0x772C7A6E+238]\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "from  bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "binary = 'chromedriver.exe'\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_experimental_option('excludeSwitches', ['enable-logging'])\n",
    "browser = webdriver.Chrome(options=options)\n",
    "\n",
    "browser.implicitly_wait(10)\n",
    "browser.get(\"https://search.naver.com/search.naver?where=image&amp;sm=stb_nmr&amp;\")\n",
    "time.sleep(10)\n",
    "elem = browser.find_element_by_id('nx_query')\n",
    "time.sleep(10)\n",
    "elem.send_keys(\"경복궁\")\n",
    "elem.submit()\n",
    "for i in range(1, 5):\n",
    "    browser.find_element_by_xpath(\"//body\").send_keys(Keys.END)\n",
    "    time.sleep(10)\n",
    "time.sleep(10)\n",
    "html = browser.page_source\n",
    "soup = BeautifulSoup(html, \"lxml\")\n",
    "def fetch_list_url():\n",
    "    params = []\n",
    "    imgList = soup.find_all(\"img\", class_=\"_img\")\n",
    "    for im in imgList:\n",
    "        try :\n",
    "            params.append(im[\"src\"])\n",
    "        except KeyError:\n",
    "            params.append(im[\"data-src\"])\n",
    "    return params\n",
    "def fetch_detail_url():\n",
    "    params = fetch_list_url()\n",
    "    for idx,p in enumerate(params,1):\n",
    "        urllib.request.urlretrieve(p, \"C:/Users/82106/project/naver/\" + str(idx) + \".jpg\")\n",
    "fetch_detail_url()\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "37febee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary = 'chromedriver.exe'\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_experimental_option('excludeSwitches', ['enable-logging'])\n",
    "browser = webdriver.Chrome(options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "62c6ba4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.get(\"https://www.google.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c51931d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-62-501ddeabc35e>:1: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  elem = browser.find_element_by_class_name('gLFyf')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "elem = browser.find_element_by_class_name('gLFyf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b64404d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "elem.send_keys(\"기모노\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a0566644",
   "metadata": {},
   "outputs": [],
   "source": [
    "elem.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d1332ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-66-172126ee6b7f>:2: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  browser.find_element_by_xpath(\"//body\").send_keys(Keys.END)\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 5):\n",
    "    browser.find_element_by_xpath(\"//body\").send_keys(Keys.END)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dba95952",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = browser.page_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d5f42004",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4d76d925",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_list_url():\n",
    "    params = []\n",
    "    imgList = soup.find_all(\"img\", class_=\"rg_i\")\n",
    "    for im in imgList:\n",
    "        try :\n",
    "            params.append(im[\"src\"])\n",
    "        except KeyError:\n",
    "            params.append(im[\"data-src\"])\n",
    "    return params\n",
    "def fetch_detail_url():\n",
    "    params = fetch_list_url()\n",
    "    for idx,p in enumerate(params,1):\n",
    "        if idx == 303:\n",
    "            continue\n",
    "        urllib.request.urlretrieve(p, \"C:/Users/82106/project/기모노/\" + str(idx) + \".jpg\")\n",
    "fetch_detail_url()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cfc9b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
